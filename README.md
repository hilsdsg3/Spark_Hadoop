<h1 align="center">Spark and Hadoop</h1> 

<br>
<p align="center">
  <a href="https://gitpoint.co/">
    <img alt="" width="450">
  </a>
</p>
<p align="center"><img width=60% src="https://github.com/hilsdsg3/Spark_Hadoop/blob/master/meta_data/pyspark_hadoop_.png"></p>

## Table of Contents

- [Definitions](#definitions)
- [Demo](#demo)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

<br>

## Definitions
<br>

Hadoop - Apache Haddop is an open source software framework for storage and large scale processing of data sets on clusters of commodity hardware.
Hadoop brings the computation to the data.

Basic modules:
1. Hadoop common contains libraries and utilities needed by other modules
2. Hadoop Distributed File System (HDFS) stores data on a commodity machine providing very high bandwidth.
3. Hadoop YARN manages a cluster and schedules users.
4. Hadoop MapReduce scales data to alot of processes.


***Running a sample DAG***
<br>
<details>
  <summary>&nbsp;&nbsp;&nbsp;1. Creating a Directed Acyclic Graph (DAG) using Python </summary>

&nbsp;&nbsp;&nbsp;Setting a variable for yesterday so we can be sure our DAG runs when we upload the Python file 
Any operators like the following will be added to the DAG object
<br>
```
hello_world_greeting >> sales_greeting >> bash_greeting
```
</details>

<details>
<summary>2. Upload the python script to the preformed bucket </summary>
<p align="center"><img width=60% src="https://github.com/hilsdsg3/Google_Cloud_Platform_Composer/blob/master/meta_data/upload_script.png"></p>


<summary>3. Open the Airflow console through the GCP Composer view </summary>
<br>

</details>
</details>
</details>

<br>
<br>








